```{r Setup, include=F}
dataPath <- "../scClustViz_files/soupTest/wc_L9648/" # path to analysis output directory

dataSpecies <- "woodchuck" #set species
dataName <- "soupTest" # name your overall analysis
sampleName <- "L9648" # name your sample


library(Matrix)
library(scales)
library(viridis)
library(biomaRt)
library(scran) # from Bioconductor
library(DropletUtils) # from Bioconductor
library(rtracklayer)
library(SoupX)

if (!file.exists(paste0(dataPath,"ebRawS.RData"))) {
  load(paste0(dataPath, "soup.RData"))
  ebRawS <- createCleanedSeurat(scl = scl)
  ebRawS <- as.SingleCellExperiment(ebRawS)
  ebRawS <- scater::calculateQCMetrics(ebRawS)
  save(ebRawS,file=paste0(dataPath,"ebRawS.RData"))
} else {
  load(paste0(dataPath,"ebRawS.RData"))
}


rm(list=ls()[!ls() %in% c("ebRawS","dataPath", "dataName","sampleName")])
gc()

rainbow2 <- function(n,a=1) {
  require(scales)
  hues = seq(15, 375, length = n + 1)
  alpha(hcl(h = hues, l = 60, c = 100)[1:n],a)
}
```


Data processing will now be performed based on a workflow published by the Marioni group (Lun et al., F1000Research 2016; http://dx.doi.org/10.12688/f1000research.9501.2).  


## Filter out low abundance genes

Noisy genes must be removed to prevent them from skewing normalization.  The filtering method in *Seurat* removes only genes detected in very few cells, which is sufficient for normalization while removing as few genes as possible. 

```{r geneFilt, echo=F,fig.height=6.3,fig.width=6.3,fig.show="hold"}
geneStats <- data.frame(DR=apply(counts(ebRawS),1,function(X) sum(X > 0)/length(X)),
                        MDTC=apply(counts(ebRawS),1,function(X) mean(X[X > 0])),
                        cellMax=apply(counts(ebRawS),1,max))
drop_g <- geneStats$DR < 3/ncol(ebRawS)
ebRawSF <- ebRawS[!drop_g,]

layout(matrix(c(2,1,0,3),2),widths=c(6,1),heights=c(1,6))
par(mar=c(3,3,0,0),mgp=2:0)
temp_H <- cut(log10(geneStats[order(geneStats$cellMax,decreasing=F),"cellMax"]),breaks=100,labels=F)
plot(log10(MDTC)~log10(DR),data=geneStats[order(geneStats$cellMax,decreasing=F),],
     pch=21,col=viridis(100,0.5,1,0)[temp_H],bg=viridis(100,0.3,1,0)[temp_H],
     xlab=expression(Log[10]~"Proportion of cells detecting gene"),
     ylab=expression(Log[10]~"Mean transcript count of detected genes (MDTC)"))
points(log10(MDTC)~log10(DR),data=geneStats[drop_g,],
       pch=4,col=alpha("red",0.5),cex=1.2)
legend("top",bty="n",pch=c(4,NA,NA),col=c("red",NA,NA),cex=1.1,inset=c(0,.06),
       legend=c("Gene in < 3 cells",
                paste("Genes removed:",sum(drop_g)),
                paste("Genes remaining:",nrow(ebRawSF))))
segments(x0=seq(quantile(range(log10(geneStats$DR)),.2),
                quantile(range(log10(geneStats$DR)),.8),length.out=1000),
         y0=rep(max(log10(geneStats$MDTC)) * 1.02),
         y1=rep(max(log10(geneStats$MDTC))),col=viridis(1000))
text(x=c(quantile(range(log10(geneStats$DR)),.2),
         median(range(log10(geneStats$DR))),
         quantile(range(log10(geneStats$DR)),.8)),
     y=rep(max(log10(geneStats$MDTC)) * .98,3),
     labels=c(min(geneStats$cellMax),
              expression(Log[10]~bold(max)~transcript~count),
              max(geneStats$cellMax)),cex=1.1)

par(mar=c(0,3,0,0))
hist(log10(geneStats$DR),freq=T,breaks=100,col="grey80",main=NULL,xaxt="n")
title("Gene expression distribution",line=-2,cex.main=1.5)
par(mar=c(3,0,0,0))
barplot(hist(log10(geneStats$MDTC),breaks=100,plot=F)$counts,
        horiz=T,space=0,col="grey80",main=NULL,xlab="Frequency")
```

```{r cleanup2, include=F}
rm(list=ls()[!ls() %in% c("ebRawSF","dataName","dataPath","plotHistHoriz","rainbow2")])
gc()
```

# Normalization  

Next step is normalization.  Marioni proposed a normalization technique that attempts to generate cell-specific size factors that are robust to differential expression between genes in a heterogenous sample, unlike simple library-size normalization (https://genomebiology.biomedcentral.com/articles/10.1186/s13059-016-0947-7).  This method correlates strongly with library size normalization for homogenous samples, but solves a series of linear equations to deconvolute cell-specific size factors for normalization.  In order to better handle heterogenous data, they suggest separating the data by simple heirarchical clustering of a Spearman correlation-based distance metric so that they can normalize the separate subpopulations separately to prevent the suppression of true differential expression during normalization.  

Normalization is carried out by assigning size factors per gene by the pooling and deconvolution method, then taking the log-ratio between each count and its size factor, and adding a pseudocount of one.  Log-transforming the data stabilizes variance by reducing the impact of a few highly variable genes.  

Following this, it is suggested to investigate sources of technical variance, but without spike-ins or any annotated possible sources of variation, this step is impossible with this data.  

```{r normalize_by_deconvolution_quickCluster, include=F}
if (!file.exists(paste0(dataPath,"ebNorm.RData"))) {
  qClust <- quickCluster(ebRawSF,min.size=200) #default
  names(qClust) <- colnames(ebRawSF)
  ebRawSF <- computeSumFactors(ebRawSF,clusters=qClust)
  ebN <- ebRawSF[,!sizeFactors(ebRawSF) <= 0]
  ebN <- normalize(ebN)
  naCells <- apply(exprs(ebN),2,function(X) any(is.na(X)))
  if (any(naCells)) {
    exprs(ebN)[,naCells] <- min(apply(exprs(ebN),1,function(X) min(X,na.rm = T)))
  }
  save(qClust,ebN,file=paste0(dataPath,"ebNorm.RData"))
} else {
  load(paste0(dataPath,"ebNorm.RData"))
}

geneStatsN <- data.frame(DR=apply(exprs(ebN),1,function(X) sum(X > 0))/ncol(ebN),
                         MDTC=apply(exprs(ebN),1,function(X) mean(X[X > 0])),
                         MTC=Matrix::rowMeans(exprs(ebN)),sumTC=Matrix::rowSums(exprs(ebN)),
                         cellMax=apply(exprs(ebN),1,max))

clustCols <- rainbow2(length(levels(qClust)))
temp_randcells <- sample.int(ncol(ebN))
```

```{r normalize_fig1, echo=F,fig.height=4.2,fig.width=8.4,fig.show="hold"}
temp_times <- as.factor(sub("_.+$","",colnames(ebRawSF)))
layout(matrix(c(2,1,0,3,5,4,0,6),2),
       widths=c(3.5,.7,3.5,.7),heights=c(.7,3.5))

## GeneDetect~LibSize by QuickCluster
par(mar=c(3,3,0,0),mgp=2:0)
plot(x=log10(colData(ebRawSF)$total_counts)[temp_randcells],
     y=log10(colData(ebRawSF)$total_features)[temp_randcells],
     pch=21,col=alpha(clustCols,0.4)[qClust][temp_randcells],
     bg=alpha(clustCols,0.2)[qClust][temp_randcells],
     xlab=expression(log[10]~"Library Size"),ylab=expression(log[10]~"Genes Detected"))
points(log10(colData(ebRawSF)$total_counts)[!colnames(ebRawSF) %in% colnames(ebN)],
       log10(colData(ebRawSF)$total_features)[!colnames(ebRawSF) %in% colnames(ebN)],
       pch=4,col="red")
mtext("Clusters for normalization",side=3,line=-1.5,font=2)
legend("topleft",bty="n",ncol=2,inset=c(0,.05),lwd=2,pch=21,
       col=alpha(clustCols[seq_along(levels(qClust))],0.3),
       pt.bg=alpha(clustCols[seq_along(levels(qClust))],0.1),
       legend=paste0(levels(qClust),": ",table(qClust)))
legend("bottomright",bty="n",pch=4,col="red",
       legend=paste(ncol(ebRawSF) - ncol(ebN),"cells could not be normalized"))

par(mar=c(0,3,.1,0))
temp_density <- tapply(log10(colData(ebRawSF)$total_counts),qClust,function(X) density(X))
plot(x=NULL,y=NULL,xlim=range(log10(colData(ebRawSF)$total_counts)),
     ylim=range(unlist(lapply(temp_density,function(X) range(X$y)))),
     xlab=NULL,ylab="Frequency",xaxt="n")
for (x in seq_along(levels(qClust))) {
  lines(temp_density[[x]],lwd=2,col=alpha(clustCols,0.7)[x])
}

par(mar=c(3,0,0,.1))
temp_density <- tapply(log10(colData(ebRawSF)$total_features),qClust,function(X) density(X))
plot(x=NULL,y=NULL,ylim=range(log10(colData(ebRawSF)$total_features)),
     xlim=range(unlist(lapply(temp_density,function(X) range(X$y)))),
     ylab=NULL,xlab="Frequency",yaxt="n")
for(x in seq_along(levels(qClust))) {
  lines(x=temp_density[[x]]$y,y=temp_density[[x]]$x,
        lwd=2,col=alpha(clustCols,0.7)[x])
}

## SizeFactor~LibSize by QuickCluster
qClustF <- qClust[colnames(ebN)]
par(mar=c(3,3,0,0),mgp=2:0)
plot(x=log10(colData(ebN)$total_counts)[temp_randcells],
     y=log10(sizeFactors(ebN))[temp_randcells],
     pch=21,col=alpha(clustCols,0.4)[qClustF][temp_randcells],
     bg=alpha(clustCols,0.2)[qClustF][temp_randcells],
     xlab=expression(log[10]~"Library Size"),ylab=expression(log[10]~"Size Factor"))
mtext("Clusters for normalization",side=3,line=-1.5,font=2)
legend("bottomright",bty="n",ncol=2,inset=c(0,.03),lwd=2,pch=21,
       col=alpha(clustCols[seq_along(levels(qClustF))],0.3),
       pt.bg=alpha(clustCols[seq_along(levels(qClustF))],0.1),
       legend=paste0(levels(qClustF),": ",table(qClustF)))
mtext(paste(ncol(ebRawSF) - ncol(ebN),"cells were not normalized"),
      side=1,line=-1.1,adj=.99,cex=.8)

par(mar=c(0,3,.1,0))
temp_density <- tapply(log10(colData(ebN)$total_counts),qClustF,function(X) density(X))
plot(x=NULL,y=NULL,xlim=range(log10(colData(ebN)$total_counts)),
     ylim=range(unlist(lapply(temp_density,function(X) range(X$y)))),
     xlab=NULL,ylab="Frequency",xaxt="n")
for (x in seq_along(levels(qClustF))) {
  lines(temp_density[[x]],lwd=2,col=alpha(clustCols,0.7)[x])
}

par(mar=c(3,0,0,.1))
temp_density <- tapply(log10(sizeFactors(ebN)),qClustF,function(X) density(X))
plot(x=NULL,y=NULL,ylim=range(log10(sizeFactors(ebN))),
     xlim=range(unlist(lapply(temp_density,function(X) range(X$y)))),
     ylab=NULL,xlab="Frequency",yaxt="n")
for(x in seq_along(levels(qClustF))) {
  lines(x=temp_density[[x]]$y,y=temp_density[[x]]$x,
        lwd=2,col=alpha(clustCols,0.7)[x])
}

```

Cells that fail to normalize are generally due to poor information content (small library size, weak gene expression relative to other cells).

```{r cleanup3, include=F}
rm(list=ls()[!ls() %in% c("ebN","dataPath")])
gc()
```

# Highly variable genes  
Identification of highly variable genes is done by assuming most endogenous genes are not variably expressed, and fitting a curve to these genes when comparing variance to mean. This curve is presumed to represent technical variation, and thus highly variable genes are those with variance significantly greater than this curve. The method used here from *scran* isn’t that different in logic to the *Seurat* method, but fitting a spline is just a little more refined way of going about it than Seurat’s binning method.

```{r HVG2, echo=F,fig.height=6.3,fig.width=8.4}
var.fit <- trendVar(exprs(ebN),method="loess",parametric=T)
var.out <- decomposeVar(exprs(ebN),var.fit)
bioCut <- 0
bioCutFDR <- 1e-2
hvg <- var.out[which(var.out$FDR <= bioCutFDR & var.out$bio >= bioCut),]
hvg <- hvg[order(hvg$bio,decreasing=T),]

par(mar=c(3,3,3,1),mgp=2:0)
plot(total~mean, data=var.out[!rownames(var.out) %in% rownames(hvg),],
     ylim=range(var.out$total),xlim=range(var.out$mean),
     pch=21,col=alpha("black",0.3),bg=alpha("black",0.1),
     xlab="Mean log-expression",ylab="Variance of log-expression")
points(total~mean, data=var.out[rownames(var.out) %in% rownames(hvg),],
       pch=21,col=alpha("red",0.3),bg=alpha("red",0.1))
lines(var.out$mean[order(var.out$mean)],var.out$tech[order(var.out$mean)],
      col=alpha("red",0.5),lwd=2)
text(total~mean,data=var.out[rownames(hvg[1:10,]),],
     labels=rownames(hvg[1:10,]),pos=4,col=alpha("red",0.5))
legend("top",bty="n",inset=c(0,-.12),ncol=2,xpd=NA,
       lwd=c(2,NA,NA),pch=c(NA,21,NA),col=alpha(c("red","red",NA),0.5),pt.bg=alpha(c(NA,"red",NA),0.3),
       legend=c("Predicted technical variance",
                paste("Biological variance > 0 at FDR <=",bioCutFDR),
                paste(nrow(hvg),"/",nrow(ebN),"highly variable genes")))
```

```{r output_for_clustering, include=F}
ebNorm <- exprs(ebN)
pDat <- colData(ebN)[,c("total_features","total_counts")]
save(ebNorm,pDat,hvg,file=paste0(dataPath,"clustInputs.RData"))

write.csv(as.matrix(exprs(ebN)),file=paste0(dataPath,"ebNorm.csv"),quote=F)
```


